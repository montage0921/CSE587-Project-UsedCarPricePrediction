{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5c5d4210-2cfa-443e-a3f6-5878298b09d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "data=pd.read_csv(r\"C:\\Users\\19692\\Downloads\\CSE587-Project-UsedCarPricePrediction\\Phase II\\Model_Q1_2_Te_Shi\\processed_data_mileage.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ed4b91c4-5281-4eb8-9b29-81753c09be3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "2021    185\n",
      "2020    158\n",
      "2019    140\n",
      "2022     95\n",
      "2018     90\n",
      "2023     87\n",
      "2017     69\n",
      "2016     52\n",
      "2015     48\n",
      "2014     35\n",
      "2024     26\n",
      "2013     15\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_weights(data, categorical_features):\n",
    "    weights = {} # percentage of different feature values in each feature is stored in this weight dict\n",
    "    for feature in categorical_features:\n",
    "        value_counts = data[feature].value_counts(normalize=True)\n",
    "        weights[feature] = value_counts.to_dict()\n",
    "    return weights\n",
    "\n",
    "def generate_synthetic_data(data, categorical_features, numeric_features, target_count,fixed_values):\n",
    "    # calculate weights for each feature\n",
    "    weights = calculate_weights(data, categorical_features)\n",
    "    \n",
    "    synthetic_data = []\n",
    "    \n",
    "    for _ in range(target_count):\n",
    "        synthetic_sample = {}\n",
    "        \n",
    "        # generate categorical features based on calculated weights\n",
    "        for feature in categorical_features:\n",
    "            if feature in fixed_values: \n",
    "                synthetic_sample[feature] = fixed_values[feature]\n",
    "            else:\n",
    "                choices = list(weights[feature].keys())\n",
    "                probabilities = list(weights[feature].values())\n",
    "                synthetic_sample[feature] = random.choices(choices, weights=probabilities, k=1)[0]\n",
    "        \n",
    "        # for some certain feature such as mileage and price, the assumption is they are in normal distribution.\n",
    "        for numeric_feature in numeric_features:\n",
    "            mean = data[numeric_feature].mean()\n",
    "            std = data[numeric_feature].std()\n",
    "            synthetic_sample[numeric_feature] = np.random.normal(mean, std)\n",
    "        \n",
    "        synthetic_data.append(synthetic_sample)\n",
    "\n",
    "    synthetic_df = pd.DataFrame(synthetic_data)\n",
    "    return synthetic_df\n",
    "\n",
    "\n",
    "categorical_features = ['make', 'year','accident_encoded']\n",
    "numeric_features = ['mileage', 'price']\n",
    "fixed_values = {'accident_encoded': 4}\n",
    "target_count = 100  # Number of synthetic records you want to generate\n",
    "\n",
    "synthetic_data = generate_synthetic_data(data, categorical_features, numeric_features, target_count,fixed_values)\n",
    "\n",
    "\n",
    "print(synthetic_data['year'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4fa287-7b7f-40ee-a356-7b64c6b21d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
